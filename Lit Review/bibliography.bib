@web_page{,
   title = {Memory Augmented Neural Network for Meta Learning — Case Study | by Mohamed Afham | the-ai.team | Medium},
   url = {https://medium.com/the-ai-team/memory-augmented-neural-network-for-meta-learning-case-study-56af9cc81ae2},
}
@article{,
   abstract = {We explore a prototypical network for k-shot classification on the Omniglot dataset. A prototypical network learns a Euclidean embeddings of images and uses their clustering for classification. This approach generalizes to different numbers of classes as well as previously unseen classes. We managed to replicate previous state of the art results on one-shot, and five-shot 20-way classification. Using a larger network, we surpassed these results by statistically significant margin. We also propose a Gaussian prototypi-cal network which, together with a vector embedding of an image, learns its covariance matrix, and uses it to construct a direction and class dependent distance metric on the embedding space. This allows the network to reflect inherent spread of images within a class. We reach state of the art results on Omniglot with this approach as well.},
   author = {Stanislav Fort},
   title = {Prototypical one-shot and k-shot learning on Omniglot using high dimensional embeddings and a mixture of Gaussians},
}
@article{Lecun2015,
   abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
   author = {Yann Lecun and Yoshua Bengio and Geoffrey Hinton},
   doi = {10.1038/NATURE14539},
   issn = {14764687},
   issue = {7553},
   journal = {Nature},
   month = {5},
   pages = {436-444},
   pmid = {26017442},
   publisher = {Nature Publishing Group},
   title = {Deep learning},
   volume = {521},
   url = {https://www.researchgate.net/publication/277411157_Deep_Learning},
   year = {2015},
}
@web_page{,
   title = {ResearchGate},
   url = {https://www.researchgate.net/publication/277411157_Deep_Learning/link/55e0cdf908ae2fac471ccf0f/download},
}
@article{Chandrasekar2014,
   abstract = {Hough Transform (HT) can provide a significant solution to the problems associated with line detection in an image. Line detection is used to detect the presence of lines in an image, at a particular orientation. The importance of line detection is used for detecting sharp changes in image brightness. HT is a popular technique in computer vision. The HT for line detection replaces the original problem of detecting collinear points in an image space by a simpler task of finding peak points in a parameter space. The proposed method used in this paper is to implement Generalized Hough Transform (GHT) on an image, since in GHT any straight line in the image is represented by a single point in the (ρ θ) parameter space and any part of this straight line is transformed into the same point. It can compute the HT of 256 × 256 test images. It can able to detect the lines present in the image and also it can extract feature points in an image.},
   author = {L. Chandrasekar and G. Durga},
   doi = {10.1109/ICCSP.2014.6949962},
   journal = {International Conference on Communication and Signal Processing, ICCSP 2014 - Proceedings},
   keywords = {Generalized Hough Transform,Hough Transform,parameter space},
   month = {11},
   pages = {843-847},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Implementation of Hough Transform for image processing applications},
   year = {2014},
}
@web_page{,
   title = {IEEE Xplore Full-Text PDF:},
   url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6949962},
}
@article{Rawat2017,
   abstract = {Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges.},
   author = {Waseem Rawat and Zenghui Wang},
   doi = {10.1162/NECO_A_00990},
   issue = {9},
   journal = {Neural Computation},
   month = {9},
   pages = {2352-2449},
   publisher = {MIT Press Journals},
   title = {Deep convolutional neural networks for image classification: A comprehensive review},
   volume = {29},
   year = {2017},
}
@web_page{,
   author = {Mai Kafafy Cheryl Danner},
   title = {Visual Chess Recognition},
   url = {https://web.stanford.edu/class/ee368/Project_Spring_1415/Reports/Danner_Kafafy.pdf},
}
@web_page{Loewke2015,
   author = {Nathan Loewke},
   title = {Depth-Based Image Segmentation},
   url = {http://stanford.edu/class/ee367/Winter2015/report_loewke.pdf},
   year = {2015},
}
@article{Tam2008,
   abstract = {Segmentation of the chessboard grid is a crucial step in coordinate extraction for chess video annotation, content-based indexing of chess videos and for content analysis in prototyping vision systems such as a chess robot. This paper deals with the segmentation of grid elements from a populated chessboard taken at a lower angle view. The proposed approach couples the line-based grid detection method with domain knowledge of the chessboard to achieve improved accuracy and reliability. © 2008 IEEE.},
   author = {K. Y. Tam and J. A. Lay and D. Levy},
   doi = {10.1109/DICTA.2008.40},
   journal = {Proceedings - Digital Image Computing: Techniques and Applications, DICTA 2008},
   pages = {294-299},
   title = {Automatic grid segmentation of populated chessboard taken at a lower angle view},
   year = {2008},
}
@article{Ziou1998,
   abstract = {In computer vision and image processing, edge detection concerns the localization of signiicant variations of the grey level image and the identiication of the physical phenomena that originated them. This information is very useful for applications in 3D reconstruction, motion, recognition, image enhancement and restoration, image registration , image compression, and so on. Usually, edge detection requires smoothing and diierentiation of the image. Diierentiation is an ill-conditioned problem and smoothing results in a loss of information. It is diicult to design a general edge detection algorithm which performs well in many contexts and captures the requirements of subsequent processing stages. Consequently, over the history of digital image processing a variety of edge detectors have been devised which diier in their mathematical and algorithmic properties. This paper is an account of the current state of our understanding of edge detection. We propose an overview of research in edge detection: edge deenition, properties of detectors, the methodology of edge detection, the mutual innuence between edges and detectors, and existing edge detectors and their implementation.},
   author = {Djemel Ziou and Salvatore Tabbone},
   title = {Edge detection techniques: An overview' Article ·},
   url = {https://www.researchgate.net/publication/312890367},
   year = {1998},
}
@article{,
   abstract = {In this paper, we present a real-time system that allows the detection of the moves of a chess game. In the proposed approach, each captured video frame, from a RGB webcam positioned over the chessboard, is processed through the following steps; the detection of the corner points of the chessboard grids, geometric rectification, chessboard position adjustment, automatic camera exposure adjustment, intensity adjustment, move detection and chessboard drawing. All steps were implemented in MATLAB programming environment without using any chess engine. The proposed approach correctly identified 162 of 164 moves in 3 games played under different illumination conditions.},
   author = {Can Koray and Emre Sümer},
   title = {A Computer Vision System for Chess Game Tracking},
}
@article{,
   abstract = {We present a computer vision application and a set of associated algorithms capable of recording chess game moves fully autonomously from the vantage point of a consumer laptop webcam. This consists of two main algorithms, (1) a hough transform-­-based algorithm for finding a homography relating board coordinates to image coordinates, and (2) a model of chessboard colors and occlusions that allows us to account for and infer piece movement in real time. We provide a video demonstration of the application applied to a real chess game and describe experiments in which our developed algorithms significantly outperform a naive baseline. All code is open sourced and available on GitHub. (See Below) Code: github.com/jayhack/CVChess Video Demo: youtube.com/watch?v=iZOA1ew-­-zYc},
   author = {Jay Hack and Prithvi Ramakrishnan},
   title = {CVChess: Computer Vision Chess Analytics},
}
@article{Czyzewski2020,
   abstract = {Chessboard and chess piece recognition is a computer vision problem that has not yet been efficiently solved. However, its solution is crucial for many experienced players who wish to compete against AI bots, but also prefer to make decisions based on the analysis of a physical chessboard. It is also important for organizers of chess tournaments who wish to digitize play for online broadcasting or ordinary players who wish to share their gameplay with friends. Typically, such digitization tasks are performed by humans or with the aid of specialized chessboards and pieces. However, neither solution is easy or convenient. To solve this problem, we propose a novel algorithm for digitizing chessboard configurations. We designed a method that is resistant to lighting conditions and the angle at which images are captured, and works correctly with numerous chessboard styles. The proposed algorithm processes pictures iteratively. During each iteration, it executes three major sub-processes: detecting straight lines, finding lattice points, and positioning the chessboard. Finally, we identify all chess pieces and generate a description of the board utilizing standard notation. For each of these steps, we designed our own algorithm that surpasses existing solutions. We support our algorithms by utilizing machine learning techniques whenever possible. The described method performs extraordinarily well and achieves an accuracy over 99.5% for detecting chessboard lattice points (compared to the 74% for the best alternative), 95% (compared to 60% for the best alternative) for positioning the chessboard in an image, and almost 95% for chess piece recognition.},
   author = {Maciej A Czyzewski and Artur Laskowski and Szymon Wasik},
   keywords = {chess,chess pieces recognition,chess-board recognition,chessboard detection,neural networks,pattern recognition},
   title = {Chessboard and Chess Piece Recognition With the Support of Neural Networks},
   year = {2020},
}
@article{Escalera2010,
   abstract = {There are increasing applications that require precise calibration of cameras to perform accurate measurements on objects located within images, and an automatic algorithm would reduce this time consuming calibration procedure. The method proposed in this article uses a pattern similar to that of a chess board, which is found automatically in each image, when no information regarding the number of rows or columns is supplied to aid its detection. This is carried out by means of a combined analysis of two Hough transforms, image corners and invariant properties of the perspective transformation. Comparative analysis with more commonly used algorithms demonstrate the viability of the algorithm proposed, as a valuable tool for camera calibration.},
   author = {Arturo De la Escalera and Jose María Armingol},
   doi = {10.3390/S100302027},
   issue = {3},
   journal = {Sensors 2010, Vol. 10, Pages 2027-2044},
   keywords = {camera calibration,chessboard detection,double Hough transform,pattern recognition},
   month = {3},
   pages = {2027-2044},
   publisher = {Molecular Diversity Preservation International},
   title = {Automatic Chessboard Detection for Intrinsic and Extrinsic Camera Parameter Calibration},
   volume = {10},
   url = {https://www.mdpi.com/1424-8220/10/3/2027/htm https://www.mdpi.com/1424-8220/10/3/2027},
   year = {2010},
}
@article{,
   abstract = {In this paper, we present a real-time system that allows the detection of the moves of a chess game. In the proposed approach, each captured video frame, from a RGB webcam positioned over the chessboard, is processed through the following steps; the detection of the corner points of the chessboard grids, geometric rectification, chessboard position adjustment, automatic camera exposure adjustment, intensity adjustment, move detection and chessboard drawing. All steps were implemented in MATLAB programming environment without using any chess engine. The proposed approach correctly identified 162 of 164 moves in 3 games played under different illumination conditions.},
   author = {Can Koray and Emre Sümer},
   title = {A Computer Vision System for Chess Game Tracking},
}
@web_page{,
   title = {Histograms of Oriented Gradients for Human Detection},
   url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1467360},
}
@article{Lowe2004,
   abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
   author = {David G Lowe},
   issue = {2},
   journal = {International Journal of Computer Vision},
   keywords = {image matching,invariant features,object recognition,scale invariance},
   pages = {91-110},
   title = {Distinctive Image Features from Scale-Invariant Keypoints},
   volume = {60},
   year = {2004},
}
@web_page{,
   title = {Chess position identification using pieces classification based on synthetic images
generation and deep neural network fine-tuning},
   url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8921043},
}
@article{,
   abstract = {This paper details a method to take an image of a chess board and output a reconstructed computer representation of the board through board and piece recognition. Though techniques for board recognition have been thoroughly explored in the past, especially in relation to chessboard calibration , previous works on piece recognition often focus on non-robust segmentation procedures that rely heavily on the exact color of customized chess boards and pieces. The method presented in this paper improves upon the segmentation-based approaches of previous work in piece recognition by introducing a novel approach using classi-fiers trained on feature descriptors, which is more robust to the similarities in color seen in real-life chess boards. This work is important for both automating the recording of moves in human chess games and improving the ability of chess-playing AI that depend on vision.},
   author = {Jialin Ding},
   title = {ChessVision: Chess Board and Piece Recognition},
}
@article{Quintana2020,
   abstract = {Automatic digitization of chess games using computer vision is a significant technological challenge. This problem is of much interest for tournament organizers and amateur or professional players to broadcast their over-the-board (OTB) games online or analyze them using chess engines. Previous work has shown promising results, but the recognition accuracy and the la-tency of state-of-the-art techniques still need further enhancements to allow their practical and affordable deployment. We have investigated how to implement them on an Nvidia Jetson Nano single-board computer effectively. Our first contribution has been accelerating the chessboard's detection algorithm. Subsequently, we have analyzed different Convolutional Neural Networks for chess piece classification and how to map them efficiently on our embedded platform. Notably, we have implemented a functional framework that automatically digitizes a chess position from an image in less than 1 second, with 92% accuracy when classifying the pieces and 95% when detecting the board.},
   author = {David Mallasén Quintana and Alberto Antonio Del Barrio and García Manuel and Prieto Matías},
   title = {LiveChess2FEN: a Framework for Classifying Chess Pieces based on CNNs},
   year = {2020},
}
@web_page{,
   title = {Attention Mechanism In Deep Learning | Attention Model Keras},
   url = {https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/},
}
@web_page{,
   title = {Advances in few-shot learning: reproducing results in PyTorch | by Oscar Knagg | Towards Data Science},
   url = {https://towardsdatascience.com/advances-in-few-shot-learning-reproducing-results-in-pytorch-aba70dee541d},
}
@web_page{,
   title = {Advances in few-shot learning: a guided tour | by Oscar Knagg | Towards Data Science},
   url = {https://towardsdatascience.com/advances-in-few-shot-learning-a-guided-tour-36bc10a68b77},
}
@article{,
   abstract = {Though deep neural networks have shown great success in the large data domain, they generally perform poorly on few-shot learning tasks, where a classifier has to quickly generalize after seeing very few examples from each class. The general belief is that gradient-based optimization in high capacity classifiers requires many iterative steps over many examples to perform well. Here, we propose an LSTM-based meta-learner model to learn the exact optimization algorithm used to train another learner neural network classifier in the few-shot regime. The parametriza-tion of our model allows it to learn appropriate parameter updates specifically for the scenario where a set amount of updates will be made, while also learning a general initialization of the learner (classifier) network that allows for quick convergence of training. We demonstrate that this meta-learning model is competitive with deep metric-learning techniques for few-shot learning.},
   author = {Sachin Ravi and Hugo Larochelle},
   title = {OPTIMIZATION AS A MODEL FOR FEW-SHOT LEARNING},
}
@article{Santoro2016,
   abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of "one-shot learning ." Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architec-tures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information , and hence can potentially obviate the down-sides of conventional models. Here, we demonstrate the ability of a memory-augmented neu-ral network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.},
   author = {Adam Santoro and Sergey Bartunov and Matthew Botvinick and Daan Wierstra and Timothy Lillicrap and Google Deepmind},
   title = {Meta-Learning with Memory-Augmented Neural Networks Google DeepMind},
   year = {2016},
}
@article{Sung2018,
   abstract = {We present a conceptually simple, flexible, and general framework for few-shot learning, where a classifier must learn to recognise new classes given only few examples from each. Our method, called the Relation Network (RN), is trained end-to-end from scratch. During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting. Once trained, a RN is able to classify images of new classes by computing relation scores between query images and the few examples of each new class without further updating the network. Besides providing improved performance on few-shot learning, our framework is easily extended to zero-shot learning. Extensive experiments on five benchmarks demonstrate that our simple approach provides a unified and effective approach for both of these two tasks.},
   author = {Flood Sung and Yongxin Yang and Li Zhang and Tao Xiang and Philip H.S. Torr and Timothy M. Hospedales},
   doi = {10.1109/CVPR.2018.00131},
   journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   month = {12},
   pages = {1199-1208},
   publisher = {IEEE Computer Society},
   title = {Learning to Compare: Relation Network for Few-Shot Learning},
   year = {2018},
}
@article{,
   abstract = {Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by Maximum Likelihood (ML) and Maximum A Posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.},
   author = {Li Fei-Fei and Rob Fergus and Pietro Perona},
   keywords = {Index Terms-Recognition,few images,learning,object categories,priors,unsupervised,variational inference},
   title = {One-Shot Learning of Object Categories},
}
@article{,
   abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
   author = {Oriol Vinyals and Google Deepmind and Charles Blundell and Timothy Lillicrap and Koray Kavukcuoglu and Daan Wierstra},
   title = {Matching Networks for One Shot Learning},
}
@article{Koch2015,
   abstract = {The process of learning good features for machine learning applications can be very computationally expensive and may prove difficult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class. In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using a convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classification tasks. ii},
   author = {Gregory Koch},
   title = {Siamese Neural Networks for One-Shot Image Recognition},
   year = {2015},
}
@article{,
   abstract = {People can learn visual concepts from just one example, but it remains a mystery how this is accomplished. Many authors have proposed that transferred knowledge from more familiar concepts is a route to one shot learning, but what is the form of this abstract knowledge? One hypothesis is that the sharing of parts is core to one shot learning, and we evaluate this idea in the domain of handwritten characters, using a massive new dataset. These simple visual concepts have a rich internal part structure, yet they are particularly tractable for computational models. We introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters. The stroke model outperforms a competing state-of-the-art character model on a challenging one shot learning task, and it provides a good fit to human perceptual data.},
   author = {Brenden M Lake and Ruslan Salakhutdinov and Jason Gross and Joshua B Tenenbaum},
   keywords = {Bayesian modeling,category learning,neural networks,transfer learning},
   title = {One shot learning of simple visual concepts},
   url = {http://web.mit.edu/brenden/www/charactervideos.html.},
}
@article{Hu2022,
   author = {Zhengping Hu and Zijun Li and Xueyu Wang and Saiyue Zheng},
   doi = {10.1016/J.PATCOG.2021.108304},
   issn = {0031-3203},
   journal = {Pattern Recognition},
   month = {2},
   pages = {108304},
   publisher = {Pergamon},
   title = {Unsupervised descriptor selection based meta-learning networks for few-shot classification},
   volume = {122},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320321004842},
   year = {2022},
}
