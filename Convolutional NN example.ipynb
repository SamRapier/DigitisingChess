{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(root_image_path):\n",
    "    labels = np.array    \n",
    "    features = []\n",
    "    # length = len(os.listdir(root_image_path))       # length should be like 67484 \n",
    "\n",
    "    length = []      # length should be like 67484 \n",
    "    count = 0\n",
    "    counter = 0\n",
    "    totalCount = 0\n",
    "    # for subdir, dirs, files in os.walk(root_image_path):    \n",
    "        # print(subdir, dirs, files)\n",
    "\n",
    "    dirs = os.listdir(root_image_path)\n",
    "    # for x in os.walk(root_image_path)[1]:\n",
    "    #     dirs = x[1]\n",
    "\n",
    "    print(dirs)\n",
    "\n",
    "\n",
    "    for dir in dirs:\n",
    "        length.append(len(os.listdir(root_image_path + str(dir))))\n",
    "        labels = np.append(labels, dir) \n",
    "            \n",
    "        # print(length, len(labels))\n",
    "\n",
    "    print(sum(length))\n",
    "\n",
    "    # for i in range(len(dirs)):\n",
    "    #     for root, _, files in os.walk(root_image_path + str(dirs[i])):\n",
    "    #         for image in files:\n",
    "    #             features.append(cv2.imread(os.path.join(root, image)))\n",
    "\n",
    "    #             if counter == 1000:\n",
    "    #                 totalCount += counter\n",
    "    #                 print(\"images processed: \" + str(totalCount))\n",
    "    #                 counter = 0\n",
    "                \n",
    "    #             counter += 1\n",
    "\n",
    "            # features[i] = features[i].reshape(3, 22500).reshape(3, 150, 150, 1)\n",
    "\n",
    "                    \n",
    "\n",
    "    # for i in range(len(features)):\n",
    "    #     features[i] = features[i].reshape(length[i], 22500).reshape(length[i], 150, 150, 1)\n",
    "    # features = features.reshape(length[i], 22,500).reshape(length[i], 150, 150, 1)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    # gets the lables and features from the directory path\n",
    "    # the images are labeled by directory-structure.\n",
    "    # with open(root_image_path, 'rb') as imagePath:\n",
    "        \n",
    "\n",
    "    #         # labels = np.append(labels, dir)\n",
    "    #         features = np.frombuffer(cv2.imread(os.path.join(subdir, image)), dtype=np.uint8, offset=16).reshape(length, 784).reshape(length, 28, 28, 1)\n",
    "\n",
    "    #         if count > 2000:\n",
    "    #             break\n",
    "\n",
    "    #         count +=1\n",
    "    return features, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features, labels = read_images('C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# # for root, _, files in os.walk('C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/bB'):\n",
    "# #     for image in files:\n",
    "# features.append(cv2.imread('C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/bB/_board_1344.jpg_0_300.jpg'))\n",
    "# print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bB', 'bK', 'bN', 'bP', 'bQ', 'bR', 'wB', 'wK', 'wN', 'wP', 'wQ', 'wR', '__']\n",
      "46369\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "root_image_path = 'C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/'\n",
    "dirs = os.listdir(root_image_path)\n",
    "\n",
    "print(dirs)\n",
    "\n",
    "\n",
    "for dir in dirs:\n",
    "    for i in range(len(os.listdir(root_image_path + str(dir)))):\n",
    "        labels.append(str(dir))\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict([(y,x) for x,y in enumerate(sorted(set(labels)))])\n",
    "int_labels = np.asarray([d[x] for x in labels])\n",
    "int_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__': 0, 'bB': 1, 'bK': 2, 'bN': 3, 'bP': 4, 'bQ': 5, 'bR': 6, 'wB': 7, 'wK': 8, 'wN': 9, 'wP': 10, 'wQ': 11, 'wR': 12}\n",
      "{0: '__', 1: 'bB', 2: 'bK', 3: 'bN', 4: 'bP', 5: 'bQ', 6: 'bR', 7: 'wB', 8: 'wK', 9: 'wN', 10: 'wP', 11: 'wQ', 12: 'wR'}\n"
     ]
    }
   ],
   "source": [
    "print(d)\n",
    "# need inverted dictionary\n",
    "inv_map = {v: k for k, v in d.items()}\n",
    "print(inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_image_path = 'C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/'\n",
    "imagePath = 'C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/bB/'\n",
    "length = len(labels)\n",
    "\n",
    "\n",
    "imageArr = []\n",
    "\n",
    "# print(files)\n",
    "dirs = os.listdir(root_image_path)\n",
    "\n",
    "for dir in dirs:\n",
    "    imagePath = root_image_path + str(dir) + '/'\n",
    "    files = os.listdir(imagePath)\n",
    "\n",
    "    for file in files:\n",
    "        image = Image.open(imagePath + file)\n",
    "\n",
    "        # imageArr.append(np.asarray(image))\n",
    "\n",
    "        # resize image and ignore original aspect ratio\n",
    "        # img_resized = image.resize((25,25))\n",
    "        imageArr.append(np.asarray(image))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.asarray(imageArr)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "validation = {}\n",
    "test = {}\n",
    "\n",
    "train['features'], test['features'], train['labels'], test['labels'] = train_test_split(features, int_labels, test_size=0.15, random_state=0)\n",
    "train['features'], validation['features'], train['labels'], validation['labels'] = train_test_split(train['features'], train['labels'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict([(y,x+1) for x,y in enumerate(sorted(set(labels)))])\n",
    "int_labels = np.asarray([d[x] for x in labels])\n",
    "int_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 31530\n",
      "# of test images: 6956\n",
      "# of validation images: 7883\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of test images:', test['features'].shape[0])\n",
    "print('# of validation images:', validation['features'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(position):\n",
    "    image = train['features'][position].squeeze()\n",
    "    plt.title('Example %d. Label: %s, %s' % (int(position), train['labels'][position], inv_map[train['labels'][position]]))\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17064/913960651.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'display_image' is not defined"
     ]
    }
   ],
   "source": [
    "display_image(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  Count\n",
       "0       1  13192\n",
       "1       2   1119\n",
       "2       3    631\n",
       "3       4   1135\n",
       "4       5   4641\n",
       "5       6    513\n",
       "6       7   1109\n",
       "7       8   1141\n",
       "8       9    538\n",
       "9      10   1150\n",
       "10     11   4545\n",
       "11     12    619\n",
       "12     13   1197"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_count = np.unique(train['labels'], return_counts=True)\n",
    "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
    "dataframe_train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (29, 29, 3)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(29,29,3)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 27, 27, 6)         168       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 13, 13, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 14)                1190      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,522\n",
      "Trainable params: 60,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], to_categorical(train['labels'])\n",
    "X_validation, y_validation = validation['features'], to_categorical(validation['labels'])\n",
    "\n",
    "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 31530\n",
      "# of validation images: 7883\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of validation images:', validation['features'].shape[0])\n",
    "\n",
    "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
    "validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "246/246 [==============================] - 13s 31ms/step - loss: 1.5777 - accuracy: 0.6693 - val_loss: 0.6641 - val_accuracy: 0.7779\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 8s 31ms/step - loss: 0.5358 - accuracy: 0.8232 - val_loss: 0.4573 - val_accuracy: 0.8527\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 4s 14ms/step - loss: 0.3741 - accuracy: 0.8785 - val_loss: 0.3585 - val_accuracy: 0.8873\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 4s 16ms/step - loss: 0.2807 - accuracy: 0.9109 - val_loss: 0.2830 - val_accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 3s 12ms/step - loss: 0.2157 - accuracy: 0.9322 - val_loss: 0.2834 - val_accuracy: 0.9129\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.1743 - accuracy: 0.9455 - val_loss: 0.2299 - val_accuracy: 0.9331\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.1424 - accuracy: 0.9559 - val_loss: 0.2508 - val_accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 3s 14ms/step - loss: 0.1204 - accuracy: 0.9620 - val_loss: 0.2265 - val_accuracy: 0.9362\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.1101 - accuracy: 0.9646 - val_loss: 0.2460 - val_accuracy: 0.9273\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.0906 - accuracy: 0.9711 - val_loss: 0.1947 - val_accuracy: 0.9502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155060351c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
    "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                    shuffle=True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 2s 8ms/step - loss: 0.1705 - accuracy: 0.9498\n",
      "Test loss: 0.17050880193710327\n",
      "Test accuracy: 0.9498274922370911\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test['features'], to_categorical(test['labels']))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
