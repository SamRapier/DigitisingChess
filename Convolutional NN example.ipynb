{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(root_image_path):\n",
    "    labels = np.array    \n",
    "    features = []\n",
    "    # length = len(os.listdir(root_image_path))       # length should be like 67484 \n",
    "\n",
    "    length = []      # length should be like 67484 \n",
    "    count = 0\n",
    "    counter = 0\n",
    "    totalCount = 0\n",
    "    # for subdir, dirs, files in os.walk(root_image_path):    \n",
    "        # print(subdir, dirs, files)\n",
    "\n",
    "    dirs = os.listdir(root_image_path)\n",
    "    # for x in os.walk(root_image_path)[1]:\n",
    "    #     dirs = x[1]\n",
    "\n",
    "    print(dirs)\n",
    "\n",
    "\n",
    "    for dir in dirs:\n",
    "        length.append(len(os.listdir(root_image_path + str(dir))))\n",
    "        labels = np.append(labels, dir) \n",
    "            \n",
    "        # print(length, len(labels))\n",
    "\n",
    "    print(sum(length))\n",
    "\n",
    "    # for i in range(len(dirs)):\n",
    "    #     for root, _, files in os.walk(root_image_path + str(dirs[i])):\n",
    "    #         for image in files:\n",
    "    #             features.append(cv2.imread(os.path.join(root, image)))\n",
    "\n",
    "    #             if counter == 1000:\n",
    "    #                 totalCount += counter\n",
    "    #                 print(\"images processed: \" + str(totalCount))\n",
    "    #                 counter = 0\n",
    "                \n",
    "    #             counter += 1\n",
    "\n",
    "            # features[i] = features[i].reshape(3, 22500).reshape(3, 150, 150, 1)\n",
    "\n",
    "                    \n",
    "\n",
    "    # for i in range(len(features)):\n",
    "    #     features[i] = features[i].reshape(length[i], 22500).reshape(length[i], 150, 150, 1)\n",
    "    # features = features.reshape(length[i], 22,500).reshape(length[i], 150, 150, 1)\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    # gets the lables and features from the directory path\n",
    "    # the images are labeled by directory-structure.\n",
    "    # with open(root_image_path, 'rb') as imagePath:\n",
    "        \n",
    "\n",
    "    #         # labels = np.append(labels, dir)\n",
    "    #         features = np.frombuffer(cv2.imread(os.path.join(subdir, image)), dtype=np.uint8, offset=16).reshape(length, 784).reshape(length, 28, 28, 1)\n",
    "\n",
    "    #         if count > 2000:\n",
    "    #             break\n",
    "\n",
    "    #         count +=1\n",
    "    return features, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features, labels = read_images('C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# # for root, _, files in os.walk('C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/bB'):\n",
    "# #     for image in files:\n",
    "# features.append(cv2.imread('C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/bB/_board_1344.jpg_0_300.jpg'))\n",
    "# print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bB', 'bK', 'bN', 'bP', 'bQ', 'bR', 'wB', 'wK', 'wN', 'wP', 'wQ', 'wR', '__']\n",
      "46369\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "root_image_path = 'C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/'\n",
    "dirs = os.listdir(root_image_path)\n",
    "\n",
    "print(dirs)\n",
    "\n",
    "\n",
    "for dir in dirs:\n",
    "    for i in range(len(os.listdir(root_image_path + str(dir)))):\n",
    "        labels.append(str(dir))\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict([(y,x+1) for x,y in enumerate(sorted(set(labels)))])\n",
    "int_labels = np.asarray([d[x] for x in labels])\n",
    "int_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_image_path = 'C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/'\n",
    "imagePath = 'C:/Users/samra/OneDrive/CompSciUni/Year4/Project/images_chess_pieces/bB/'\n",
    "length = len(labels)\n",
    "\n",
    "\n",
    "imageArr = []\n",
    "\n",
    "# print(files)\n",
    "dirs = os.listdir(root_image_path)\n",
    "\n",
    "for dir in dirs:\n",
    "    imagePath = root_image_path + str(dir) + '/'\n",
    "    files = os.listdir(imagePath)\n",
    "\n",
    "    for file in files:\n",
    "        image = Image.open(imagePath + file)\n",
    "\n",
    "        # imageArr.append(np.asarray(image))\n",
    "\n",
    "        # resize image and ignore original aspect ratio\n",
    "        img_resized = image.resize((25,25))\n",
    "        imageArr.append(np.asarray(img_resized))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.asarray(imageArr)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "validation = {}\n",
    "test = {}\n",
    "\n",
    "train['features'], test['features'], train['labels'], test['labels'] = train_test_split(features, int_labels, test_size=0.15, random_state=0)\n",
    "train['features'], validation['features'], train['labels'], validation['labels'] = train_test_split(train['features'], train['labels'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict([(y,x+1) for x,y in enumerate(sorted(set(labels)))])\n",
    "int_labels = np.asarray([d[x] for x in labels])\n",
    "int_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 31530\n",
      "# of test images: 6956\n",
      "# of validation images: 7883\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of test images:', test['features'].shape[0])\n",
    "print('# of validation images:', validation['features'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(position):\n",
    "    image = train['features'][position].squeeze()\n",
    "    plt.title('Example %d. Label: %s' % (int(position), train['labels'][position]))\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(20070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  Count\n",
       "0       1  13192\n",
       "1       2   1119\n",
       "2       3    631\n",
       "3       4   1135\n",
       "4       5   4641\n",
       "5       6    513\n",
       "6       7   1109\n",
       "7       8   1141\n",
       "8       9    538\n",
       "9      10   1150\n",
       "10     11   4545\n",
       "11     12    619\n",
       "12     13   1197"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_count = np.unique(train['labels'], return_counts=True)\n",
    "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
    "dataframe_train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (29, 29, 3)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(29,29,3)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=14, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 27, 27, 6)         168       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 13, 13, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 14)                1190      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,522\n",
      "Trainable params: 60,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], to_categorical(train['labels'])\n",
    "X_validation, y_validation = validation['features'], to_categorical(validation['labels'])\n",
    "\n",
    "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 31530\n",
      "# of validation images: 7883\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of validation images:', validation['features'].shape[0])\n",
    "\n",
    "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
    "validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "246/246 [==============================] - 13s 31ms/step - loss: 1.5777 - accuracy: 0.6693 - val_loss: 0.6641 - val_accuracy: 0.7779\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 8s 31ms/step - loss: 0.5358 - accuracy: 0.8232 - val_loss: 0.4573 - val_accuracy: 0.8527\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 4s 14ms/step - loss: 0.3741 - accuracy: 0.8785 - val_loss: 0.3585 - val_accuracy: 0.8873\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 4s 16ms/step - loss: 0.2807 - accuracy: 0.9109 - val_loss: 0.2830 - val_accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 3s 12ms/step - loss: 0.2157 - accuracy: 0.9322 - val_loss: 0.2834 - val_accuracy: 0.9129\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.1743 - accuracy: 0.9455 - val_loss: 0.2299 - val_accuracy: 0.9331\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.1424 - accuracy: 0.9559 - val_loss: 0.2508 - val_accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 3s 14ms/step - loss: 0.1204 - accuracy: 0.9620 - val_loss: 0.2265 - val_accuracy: 0.9362\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.1101 - accuracy: 0.9646 - val_loss: 0.2460 - val_accuracy: 0.9273\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.0906 - accuracy: 0.9711 - val_loss: 0.1947 - val_accuracy: 0.9502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155060351c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
    "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                    shuffle=True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 2s 8ms/step - loss: 0.1705 - accuracy: 0.9498\n",
      "Test loss: 0.17050880193710327\n",
      "Test accuracy: 0.9498274922370911\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test['features'], to_categorical(test['labels']))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
